[34m[1mwandb[39m[22m: [33mWARNING[39m Config item 'learning_rate' was locked by 'sweep' (ignored update).
[34m[1mwandb[39m[22m: [33mWARNING[39m Config item 'num_epochs' was locked by 'sweep' (ignored update).
[34m[1mwandb[39m[22m: [33mWARNING[39m Config item 'hidden_size' was locked by 'sweep' (ignored update).
[34m[1mwandb[39m[22m: [33mWARNING[39m Config item 'num_layers' was locked by 'sweep' (ignored update).
[34m[1mwandb[39m[22m: [33mWARNING[39m Config item 'dropout' was locked by 'sweep' (ignored update).
[34m[1mwandb[39m[22m: [33mWARNING[39m Config item 'weight_decay' was locked by 'sweep' (ignored update).
  0%|                                                                                              | 0/20 [00:00<?, ?it/s]
Creating dataset...
Loading data from /home/usuaris/veu/gerard.calvo.bartra/nuwe/model/../data/supply_chain_train_raw.csv
Train batch 0:
{'data': tensor([[-0.4864, -1.4176, -0.2530,  ...,  0.0000,  0.0000,  0.0000],
        [-0.7458,  0.6977, -1.0240,  ...,  0.0000,  0.0000,  0.0000],
        [-0.8396,  0.8221, -1.0240,  ...,  0.0000,  0.0000,  0.0000],
        ...,
        [ 1.5378,  0.3244,  0.5180,  ...,  0.0000,  0.0000,  0.0000],
        [-0.6004, -0.1733,  0.5180,  ...,  0.0000,  0.0000,  0.0000],
        [-0.6533, -0.5466,  0.5180,  ...,  0.0000,  0.0000,  0.0000]],
       dtype=torch.float64), 'target': tensor([1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0,
        1, 1, 1, 1, 0, 1, 1, 1])}
Validation batch 0:
{'data': tensor([[-0.7021, -0.9862, -0.2985,  ...,  0.0000,  0.0000,  0.0000],
        [-0.7690,  0.4015,  2.1085,  ...,  0.0000,  0.0000,  1.0000],
        [-0.7355,  0.0231, -1.1008,  ...,  0.0000,  0.0000,  0.0000],
        ...,
        [-0.7259,  0.1492, -0.2985,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.4713,  0.5277,  2.1085,  ...,  0.0000,  0.0000,  0.0000],
        [-0.7987, -0.2293,  0.5039,  ...,  0.0000,  0.0000,  0.0000]],
       dtype=torch.float64), 'target': tensor([1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 0, 1, 1])}
batch_data.shape: torch.Size([32, 38])
Percentage of positive and negative samples in the training set:
1    0.839094
0    0.160906
Name: Attrition_Flag, dtype: float64
BaselineNet(
  (fc): Sequential(
    (fc0): Linear(in_features=38, out_features=512, bias=True)
    (relu0): ReLU()
    (dropout0): Dropout(p=0.16129545100683257, inplace=False)
    (fc1): Linear(in_features=512, out_features=512, bias=True)
    (relu1): ReLU()
    (dropout1): Dropout(p=0.16129545100683257, inplace=False)
    (fc2): Linear(in_features=512, out_features=512, bias=True)
    (relu2): ReLU()
    (dropout2): Dropout(p=0.16129545100683257, inplace=False)
    (fc3): Linear(in_features=512, out_features=1, bias=True)
    (sigmoid): Sigmoid()
  )
)
Num params:  545793

  5%|████▎                                                                                 | 1/20 [00:04<01:21,  4.32s/it]
Epoch 0 (train) - Loss: 0.252

 10%|████████▌                                                                             | 2/20 [00:08<01:15,  4.17s/it]
Epoch 1 (train) - Loss: 0.185

 15%|████████████▉                                                                         | 3/20 [00:12<01:09,  4.08s/it]
Epoch 2 (train) - Loss: 0.167

 20%|█████████████████▏                                                                    | 4/20 [00:16<01:04,  4.06s/it]
Epoch 3 (train) - Loss: 0.156

 25%|█████████████████████▌                                                                | 5/20 [00:20<01:01,  4.11s/it]
Epoch 4 (train) - Loss: 0.147
Epoch 4 (test) - Accuracy: 0.944 - F1 score: 0.967
Epoch 5 (train) - Loss: 0.141

 30%|█████████████████████████▊                                                            | 6/20 [00:24<00:57,  4.13s/it]
Epoch 6 (train) - Loss: 0.136

 35%|██████████████████████████████                                                        | 7/20 [00:29<00:54,  4.21s/it]
Epoch 7 (train) - Loss: 0.133

 40%|██████████████████████████████████▍                                                   | 8/20 [00:34<00:53,  4.45s/it]
Epoch 8 (train) - Loss: 0.122

 45%|██████████████████████████████████████▋                                               | 9/20 [00:39<00:52,  4.75s/it]
Epoch 9 (train) - Loss: 0.118

 50%|██████████████████████████████████████████▌                                          | 10/20 [00:45<00:50,  5.01s/it]
Epoch 10 (train) - Loss: 0.115

 55%|██████████████████████████████████████████████▊                                      | 11/20 [00:50<00:45,  5.10s/it]
Epoch 11 (train) - Loss: 0.111

 60%|███████████████████████████████████████████████████                                  | 12/20 [00:55<00:41,  5.22s/it]
Epoch 12 (train) - Loss: 0.105

 65%|███████████████████████████████████████████████████████▎                             | 13/20 [01:01<00:37,  5.30s/it]
Epoch 13 (train) - Loss: 0.098

 70%|███████████████████████████████████████████████████████████▍                         | 14/20 [01:06<00:31,  5.31s/it]
Epoch 14 (train) - Loss: 0.100

 75%|███████████████████████████████████████████████████████████████▊                     | 15/20 [01:12<00:27,  5.43s/it]
Epoch 15 (train) - Loss: 0.096

 80%|████████████████████████████████████████████████████████████████████                 | 16/20 [01:18<00:22,  5.53s/it]
Epoch 16 (train) - Loss: 0.086

 85%|████████████████████████████████████████████████████████████████████████▎            | 17/20 [01:23<00:16,  5.51s/it]
Epoch 17 (train) - Loss: 0.083

 90%|████████████████████████████████████████████████████████████████████████████▌        | 18/20 [01:29<00:10,  5.47s/it]
Epoch 18 (train) - Loss: 0.086

 95%|████████████████████████████████████████████████████████████████████████████████▊    | 19/20 [01:34<00:05,  5.51s/it]
Epoch 19 (train) - Loss: 0.079
Epoch 19 (test) - Accuracy: 0.948 - F1 score: 0.969
Plotting the results...
Saving the plot as 'results_baseline_model_2_raw.png'...
Saving the model as 'baseline_model_2_raw'...

100%|█████████████████████████████████████████████████████████████████████████████████████| 20/20 [01:40<00:00,  5.00s/it]
Done!